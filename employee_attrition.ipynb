{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and IA Orange Summer Challenge 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation et Exploration des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/WA_Fn-UseC_-HR-Employee-Attrition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display of descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing Numerical Values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après la description numérique ci-dessus, les colonnes telles que l'âge, le taux journalier et l'éducation ont une distribution équilibrée des valeurs. Il n'y a pas d'asymétrie significative (valeurs extrêmes ou données très élevées/faibles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Outliers with Interquartile Range (IQR)\n",
    "q1 = df['YearsAtCompany'].quantile(0.25)\n",
    "q3 = df['YearsAtCompany'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "df[(df['YearsAtCompany'] < lower_bound) | (df['YearsAtCompany'] > upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutefois, les colonnes présentant de grandes différences entre la moyenne et la médiane, telles que TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion et YearsWithCurrentManager, présentent des valeurs aberrantes, comme le montre le code ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing Categorical Values\n",
    "df.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the categorical description, we can conclude points such as:\n",
    "\n",
    "Most of the values in Attrition is No, meaning most employees resigned\n",
    "Most employees are Sales Executives\n",
    "There are more Male employees compared to Female employees\n",
    "Most employees are Married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null Data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n",
    "# There are no duplicated values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "# There are no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means the dataset has no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation et prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColsBox = df.select_dtypes('int64')\n",
    "for col in ColsBox.columns:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('box plot of '+col)\n",
    "    sns.boxplot(df[col])\n",
    "    plt.show()\n",
    "\n",
    "# Drop Outlier Datas\n",
    "df.drop(df[(df['TotalWorkingYears'] < lower_bound) | (df['TotalWorkingYears'] > upper_bound)]. index, inplace = True)\n",
    "df.drop(df[(df['YearsAtCompany'] < lower_bound) | (df['YearsAtCompany'] > upper_bound)]. index, inplace = True)\n",
    "df.drop(df[(df['YearsInCurrentRole'] < lower_bound) | (df['YearsInCurrentRole'] > upper_bound)]. index, inplace = True)\n",
    "df.drop(df[(df['YearsSinceLastPromotion'] < lower_bound) | (df['YearsSinceLastPromotion'] > upper_bound)]. index, inplace = True)\n",
    "df.drop(df[(df['YearsWithCurrManager'] < lower_bound) | (df['YearsWithCurrManager'] > upper_bound)]. index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, columns 'EmployeeCount', 'Over18', 'StandardHours' contain only one unique value (all rows have the same values), which will not be useful later on. These columns will also be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Data with Only One Unique Value\n",
    "df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming categorical values into numerical values\n",
    "\n",
    "mapping = {\"Yes\": 1, \"No\": 0}\n",
    "df[\"Attrition\"] = df[\"Attrition\"].replace(mapping)\n",
    "df[\"Attrition\"] = df[\"Attrition\"].astype(\"int64\")\n",
    "df[\"OverTime\"] = df[\"OverTime\"].replace(mapping)\n",
    "df[\"OverTime\"] = df[\"OverTime\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping2 = {\"Non-Travel\": 0, \"Travel_Rarely\": 1, \"Travel_Frequently\": 2}\n",
    "df[\"BusinessTravel\"] = df[\"BusinessTravel\"].replace(mapping2)\n",
    "df[\"BusinessTravel\"] = df[\"BusinessTravel\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping3 = {\"Research & Development\" : 0, \"Sales\" : 1, \"Human Resources\" : 2}\n",
    "df[\"Department\"] = df[\"Department\"].replace(mapping3)\n",
    "df[\"Department\"] = df[\"Department\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping4 = {\"Life Sciences\": 0, \"Medical\": 1, \"Marketing\" : 2,\"Technical Degree\" : 3, \"Human Resources\" : 4, \"Other\" : 5  }\n",
    "df[\"EducationField\"] = df[\"EducationField\"].replace(mapping4)\n",
    "df[\"EducationField\"] = df[\"EducationField\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping5 = {\"Male\": 1, \"Female\": 0}\n",
    "df[\"Gender\"] = df[\"Gender\"].replace(mapping5)\n",
    "df[\"Gender\"] = df[\"Gender\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping6 = {\"Human Resources\": 8, \"Manager\": 7,\"Healthcare Representative\": 6,\"Manufacturing Director\": 5, \"Laboratory Technician\" : 4,\"Sales Representative\": 3, \"Sales Executive\": 2,\"Research Director\":1, \"Research Scientist\": 0}\n",
    "df[\"JobRole\"] = df[\"JobRole\"].replace(mapping6)\n",
    "df[\"JobRole\"] = df[\"JobRole\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping7 = {\"Divorced\": 2,\"Married\": 1, \"Single\": 0}\n",
    "df[\"MaritalStatus\"] = df[\"MaritalStatus\"].replace(mapping7)\n",
    "df[\"MaritalStatus\"] = df[\"MaritalStatus\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "Which columns have the top 5 highest correlations with each other?\n",
    "What factor influences employee's rate of attrition the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations Matrix in Regards to Attrition\n",
    "\n",
    "# Selects 10 columns that has the highest correlation to Attrition\n",
    "col = df.corr().nlargest(10, \"Attrition\").Attrition.index\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(df[col].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", annot_kws={\"size\":15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix (all columns)\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", annot_kws={\"size\":15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 Highest Correlations\n",
    "\n",
    "- JobLevel affects MonthlyIncome (0.88)\n",
    "- YearsInCurrentRole affects YearsAtCompany (0.86)\n",
    "- YearsAtCompany affects YearsWithCurrManager (0.85)\n",
    "- PerformanceRating affects PercentSalaryHike (0.77)\n",
    "- YearsInCurrentRole affects YearsWithCurrentManager (0.74)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attrition predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict Attrition we should use a classification model, because this is a binary variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix, recall_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('Attrition', axis=1), df['Attrition'], test_size=0.2, random_state=33)\n",
    "\n",
    "# Using solver='lbfgs' option to implement regularization\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "# Checking the score\n",
    "logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is used to evaluate the performance of a classification model. It operates such metrics of predictions as:\n",
    "\n",
    "- True Positive (TP): Correct positive prediction\n",
    "- False Positive (FP): Incorrect positive prediction, real label is negative\n",
    "- False Negative (FN): Incorrect negative prediction, real label is positive\n",
    "- True Negative (TN): Correct negative prediction\n",
    "\n",
    "It looks like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's build a confusion matrix\n",
    "\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. LogisticRegressionCV\n",
    "\n",
    "This model is a subclass of LogisticRegression, but includes cross-validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('Attrition', axis=1), df['Attrition'], test_size=0.2, random_state=33)\n",
    "\n",
    "logreg = LogisticRegressionCV(max_iter=10000)\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "# Checking the score\n",
    "logreg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. KNeighborsClassifier¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('Attrition', axis=1), df['Attrition'], test_size=0.2, random_state=33)\n",
    "\n",
    "# Create a KNN model and fit it to the training data\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Checking the score on the training set\n",
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
